{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.3.1+cu121 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): NVIDIA GeForce RTX 3080\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import check_torch\n",
    "device = check_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid: (100, 100, 11) | Tops: (100, 100, 11)\n",
      "Grid_ext: (33, 100, 100, 11) | Grid_short_ext: (33, 100, 100, 5)\n"
     ]
    }
   ],
   "source": [
    "sec2year   = 365.25 * 24 * 60 * 60\n",
    "psi2pascal = 6894.76\n",
    "co2_rho    = 686.5266\n",
    "mega       = 1e6\n",
    "\n",
    "n_timesteps = 33\n",
    "nx, ny, nz, nz_short  = 100, 100, 11, 5\n",
    "\n",
    "indexMap = loadmat('data_100_100_11/G_cells_indexMap.mat', simplify_cells=True)['gci']\n",
    "Grid = np.zeros((nx,ny,nz)).flatten(order='F')\n",
    "Grid[indexMap] = 1\n",
    "Grid = Grid.reshape(nx,ny,nz, order='F')\n",
    "Tops = np.load('data_npy_100_100_11/tops_grid.npz')['tops']\n",
    "print('Grid: {} | Tops: {}'.format(Grid.shape, Tops.shape))\n",
    "\n",
    "Grid_short = Grid[:,:,5:10]\n",
    "Grid_ext = np.repeat(np.expand_dims(Grid, 0), 33, axis=0)\n",
    "Grid_short_ext = np.repeat(np.expand_dims(Grid_short, 0), 33, axis=0)\n",
    "print('Grid_ext: {} | Grid_short_ext: {}'.format(Grid_ext.shape, Grid_short_ext.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xx (5, 6, 100, 100, 5)\n",
      "yy (5, 33, 2, 100, 100, 5)\n"
     ]
    }
   ],
   "source": [
    "train_idx = np.random.choice(range(1272), size=5, replace=False)\n",
    "test_idx  = np.setdiff1d(range(1272), train_idx)\n",
    "\n",
    "xm = np.zeros((len(train_idx), 3, 100,100,5))\n",
    "xw = np.zeros((len(train_idx), 2, 5))\n",
    "xc = np.zeros((len(train_idx), n_timesteps, 5))\n",
    "xt = np.zeros((len(train_idx), n_timesteps, 1))\n",
    "yy = np.zeros((len(train_idx), 33, 2, 100,100,5))\n",
    "\n",
    "def apply_mask(x, imap=indexMap, mask_value=0.0):\n",
    "    xx = mask_value*np.ones((nx,ny,nz)).flatten(order='F')\n",
    "    xx[imap] = x.flatten(order='F')[imap]\n",
    "    xx = xx.reshape((nx,ny,nz), order='F')\n",
    "    return xx\n",
    "\n",
    "for i in range(len(train_idx)):\n",
    "    m = np.load('data_npy_100_100_11/inputs_rock_rates_locs_time/x_{}.npz'.format(train_idx[i]))\n",
    "    p = np.expand_dims(apply_mask(m['poro']), 0)[...,5:10] / 0.3\n",
    "    k = np.expand_dims(apply_mask(m['perm']), 0)[...,5:10] / 3.3\n",
    "    t = np.expand_dims(apply_mask(Tops), 0)[...,5:10]      / Tops.max()\n",
    "    xm[i] = np.concatenate([t, p, k], 0)\n",
    "\n",
    "    xw[i] = m['locs']\n",
    "    xc[i] = m['ctrl']\n",
    "    xt[i] = m['time']\n",
    "\n",
    "    dd = np.load('data_npy_100_100_11/outputs_pressure_saturation/y_{}.npz'.format(train_idx[i]))\n",
    "    prm = dd['pressure'][...,5:10]\n",
    "    sam = dd['saturation'][...,5:10]\n",
    "    yy[i,:,0] = np.expand_dims(prm, 0)\n",
    "    yy[i,:,1] = np.expand_dims(sam, 0)\n",
    "\n",
    "inj_locs  = np.zeros((len(train_idx), 1, 100,100,5))\n",
    "inj_rates = np.zeros((len(train_idx), 1, 100,100,5))\n",
    "inj_times = np.zeros((len(train_idx), 1, 100,100,5))\n",
    "for i in range(len(train_idx)):\n",
    "    inj_locs[i, 0, xw[i][0,:].astype(int), xw[i][1,:].astype(int), :] = 1\n",
    "    inj_rates[i] = np.expand_dims(np.repeat(np.expand_dims(np.concatenate([np.zeros((1,100)),\n",
    "                                      np.repeat(np.repeat(xc[1],20,axis=-1),3,axis=0)],\n",
    "                                      axis=0), -1), 5, axis=-1),0)\n",
    "    inj_times[i] = np.repeat(np.expand_dims(np.expand_dims(np.concatenate([np.zeros((1,100)),\n",
    "                                      np.repeat(np.repeat(xt[0],3,axis=0),100,axis=1)],axis=0),0),-1), 5, axis=-1)\n",
    "\n",
    "xx = np.concatenate([xm, inj_locs, inj_rates, inj_times], 1)\n",
    "\n",
    "print('xx', xx.shape)\n",
    "print('yy', yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True):\n",
    "        super(SeparableConv3d, self).__init__()\n",
    "\n",
    "        self.depthwise = nn.Conv3d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=in_channels,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "        self.pointwise = nn.Conv3d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcite3d(nn.Module):\n",
    "    def __init__(self, channels, ratio=4):\n",
    "        super(SqueezeExcite3d, self).__init__()\n",
    "        self.ratio = ratio\n",
    "        self.squeeze = nn.AdaptiveAvgPool3d(1)\n",
    "        self.excite1 = nn.Linear(channels, channels//ratio)\n",
    "        self.excite2 = nn.Linear(channels//ratio, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w, d = x.size()\n",
    "        se_tensor = self.squeeze(x).view(b,c)\n",
    "        se_tensor = F.relu(self.excite1(se_tensor))\n",
    "        se_tensor = torch.sigmoid(self.excite2(se_tensor)).view(b,c,1,1,1)\n",
    "        scaled_inputs = x * se_tensor.expand_as(x)\n",
    "        return x + scaled_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels:list, return_hidden_states:bool=False,\n",
    "                 kernel_size=3, stride=1, padding=1, dilation=1, bias=True, \n",
    "                 pool_size=(2,2,1), dropout_rate=0.1):\n",
    "        super(SpatialEncoder, self).__init__()\n",
    "        assert len(hidden_channels) == 3, 'Hidden channels must be a list of 3 integers'\n",
    "        c1, c2, c3 = hidden_channels\n",
    "        self.return_hidden_states = return_hidden_states\n",
    "        self.conv1 = SeparableConv3d(in_channels, c1, kernel_size, stride, padding, dilation, bias)\n",
    "        self.sae1  = SqueezeExcite3d(c1)\n",
    "        self.norm1 = nn.GroupNorm(c1, c1)\n",
    "\n",
    "        self.conv2 = SeparableConv3d(c1, c2, kernel_size, stride, padding, dilation, bias)\n",
    "        self.sae2  = SqueezeExcite3d(c2)\n",
    "        self.norm2 = nn.GroupNorm(c2, c2)\n",
    "\n",
    "        self.conv3 = SeparableConv3d(c2, c3, kernel_size, stride, padding, dilation, bias)\n",
    "        self.sae3  = SqueezeExcite3d(c3)\n",
    "        self.norm3 = nn.GroupNorm(c3, c3)\n",
    "\n",
    "        self.pool = nn.MaxPool3d(pool_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.drop = nn.Dropout3d(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sae1(self.conv1(x))\n",
    "        x1 = x\n",
    "        x = self.drop(self.pool(self.gelu(self.norm1(x))))\n",
    "        x = self.sae2(self.conv2(x))\n",
    "        x2 = x\n",
    "        x = self.drop(self.pool(self.gelu(self.norm2(x))))\n",
    "        x = self.sae3(self.conv3(x))\n",
    "        x3 = x\n",
    "        x = self.drop(self.pool(self.gelu(self.norm3(x))))\n",
    "\n",
    "        if self.return_hidden_states:\n",
    "            return x, (x1,x2,x3)\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_m torch.Size([1, 3, 100, 100, 5])\n",
      "zm torch.Size([1, 256, 12, 12, 5])\n"
     ]
    }
   ],
   "source": [
    "temp_m = torch.tensor(np.expand_dims(xm[0], 0), dtype=torch.float32)\n",
    "print('temp_m', temp_m.shape)\n",
    "\n",
    "spatial_encoder = SpatialEncoder(3, [16,64,256], return_hidden_states=True)\n",
    "\n",
    "zm, hm = spatial_encoder(temp_m)\n",
    "print('zm', zm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xw (5, 2, 5)\n",
      "xc (5, 33, 5)\n",
      "xt (5, 33, 1)\n",
      "yy (5, 33, 2, 100, 100, 5)\n"
     ]
    }
   ],
   "source": [
    "print('xw', xw.shape)\n",
    "print('xc', xc.shape)\n",
    "print('xt', xt.shape)\n",
    "print('yy', yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiftingLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LiftingLayer, self).__init__()\n",
    "        self.fc   = nn.Linear(in_features, out_features)\n",
    "        self.norm = nn.LayerNorm(out_features)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.gelu(self.norm(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList([LiftingLayer(in_features, out_features) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_w torch.Size([1, 10])\n",
      "zw torch.Size([1, 1024])\n",
      "temp_c torch.Size([1, 165])\n",
      "zc torch.Size([1, 1024])\n",
      "temp_t torch.Size([1, 33])\n",
      "zt torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "temp_w = torch.tensor(np.expand_dims(xw[0].flatten(), 0), dtype=torch.float32)\n",
    "temp_c = torch.tensor(np.expand_dims(xc[0].flatten(), 0), dtype=torch.float32)\n",
    "temp_t = torch.tensor(np.expand_dims(xt[0].flatten(), 0), dtype=torch.float32)\n",
    "\n",
    "lift_w = LiftingLayer(2*5, 1024)\n",
    "lift_c = LiftingLayer(33*5, 1024)\n",
    "lift_t = LiftingLayer(33, 1024)\n",
    "\n",
    "branch_w = DenseBlock(1024, 1024, 5)\n",
    "branch_c = DenseBlock(1024, 1024, 5)\n",
    "trunk_t  = DenseBlock(1024, 1024, 5)\n",
    "\n",
    "print('temp_w', temp_w.shape)\n",
    "zw = lift_w(temp_w)\n",
    "zw = branch_w(zw)\n",
    "print('zw', zw.shape)\n",
    "\n",
    "print('temp_c', temp_c.shape)\n",
    "zc = lift_c(temp_c)\n",
    "zc = branch_c(zc)\n",
    "print('zc', zc.shape)\n",
    "\n",
    "print('temp_t', temp_t.shape)\n",
    "zt = lift_t(temp_t)\n",
    "zt = trunk_t(zt)\n",
    "print('zt', zt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM3DCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, bias=True):\n",
    "        super(ConvLSTM3DCell, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels=self.input_channels + self.hidden_channels,\n",
    "                              out_channels=4 * self.hidden_channels,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        combined = torch.cat([x, h], dim=1)\n",
    "        conv_output = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(conv_output, self.hidden_channels, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM3DCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, bias=True):\n",
    "        super(ConvLSTM3DCell, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels=self.input_channels + self.hidden_channels,\n",
    "                              out_channels=4 * self.hidden_channels,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        combined = torch.cat([x, h], dim=1)\n",
    "        conv_output = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(conv_output, self.hidden_channels, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        depth, height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_channels, depth, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_channels, depth, height, width, device=self.conv.weight.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM3DCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, bias=True):\n",
    "        super(ConvLSTM3DCell, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels=self.input_channels + self.hidden_channels,\n",
    "                              out_channels=4 * self.hidden_channels,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        combined = torch.cat([x, h], dim=1)\n",
    "        conv_output = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(conv_output, self.hidden_channels, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        depth, height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_channels, depth, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_channels, depth, height, width, device=self.conv.weight.device))\n",
    "\n",
    "\n",
    "class ConvLSTM3D(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, num_layers, batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM3D, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_channels = self.input_channels if i == 0 else self.hidden_channels[i - 1]\n",
    "            cell_list.append(ConvLSTM3DCell(input_channels=cur_input_channels,\n",
    "                                            hidden_channels=self.hidden_channels[i],\n",
    "                                            kernel_size=self.kernel_size,\n",
    "                                            bias=self.bias))\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, x, hidden_state=None):\n",
    "        if not self.batch_first:\n",
    "            x = x.permute(1, 0, 2, 3, 4, 5)\n",
    "\n",
    "        b, _, _, d, h, w = x.size()\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self._init_hidden(batch_size=b,\n",
    "                                             image_size=(d, h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = x.size(1)\n",
    "        cur_layer_input = x\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](x=cur_layer_input[:, t, :, :, :, :],\n",
    "                                                 h=h, c=c)\n",
    "                output_inner.append(h)\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            layer_output_list = layer_output_list[0]\n",
    "            last_state_list = last_state_list[0]\n",
    "            \n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvLSTM3D(input_channels=256, hidden_channels=[64, 16, 4], kernel_size=3, num_layers=3, \n",
    "                   batch_first=True, bias=True, return_all_layers=True)\n",
    "\n",
    "input_tensor = torch.rand(1, 33, 256, 12, 12, 5)\n",
    "\n",
    "zd, hd = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
