{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.1.2+cu118 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): Quadro M6000 24GB\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from temp import NeuralPix2Vid\n",
    "from neuralop.models import FNO\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from temp import check_torch\n",
    "device = check_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid: (100, 100, 11) | Tops: (100, 100, 11)\n",
      "Grid_ext: (33, 100, 100, 11) | Grid_short_ext: (33, 100, 100, 5)\n"
     ]
    }
   ],
   "source": [
    "sec2year   = 365.25 * 24 * 60 * 60\n",
    "psi2pascal = 6894.76\n",
    "co2_rho    = 686.5266\n",
    "mega       = 1e6\n",
    "\n",
    "n_timesteps = 33\n",
    "nx, ny, nz, nz_short  = 100, 100, 11, 5\n",
    "\n",
    "indexMap = loadmat('data_100_100_11/G_cells_indexMap.mat', simplify_cells=True)['gci']\n",
    "Grid = np.zeros((nx,ny,nz)).flatten(order='F')\n",
    "Grid[indexMap] = 1\n",
    "Grid = Grid.reshape(nx,ny,nz, order='F')\n",
    "Tops = np.load('data_npy_100_100_11/tops_grid.npz')['tops']\n",
    "print('Grid: {} | Tops: {}'.format(Grid.shape, Tops.shape))\n",
    "\n",
    "Grid_short = Grid[:,:,5:10]\n",
    "Grid_ext = np.repeat(np.expand_dims(Grid, 0), 33, axis=0)\n",
    "Grid_short_ext = np.repeat(np.expand_dims(Grid_short, 0), 33, axis=0)\n",
    "print('Grid_ext: {} | Grid_short_ext: {}'.format(Grid_ext.shape, Grid_short_ext.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 50\n",
    "\n",
    "train_idx = np.random.choice(range(1272), size=train_size, replace=False)\n",
    "test_idx  = np.setdiff1d(range(1272), train_idx)\n",
    "\n",
    "xm = np.zeros((len(train_idx), 3, 100,100,5))\n",
    "xw = np.zeros((len(train_idx), 2, 5))\n",
    "xc = np.zeros((len(train_idx), n_timesteps, 5))\n",
    "xt = np.zeros((len(train_idx), n_timesteps, 1))\n",
    "yy = np.zeros((len(train_idx), 33, 2, 100,100,5))\n",
    "\n",
    "def apply_mask(x, imap=indexMap, mask_value=0.0):\n",
    "    xx = mask_value*np.ones((nx,ny,nz)).flatten(order='F')\n",
    "    xx[imap] = x.flatten(order='F')[imap]\n",
    "    xx = xx.reshape((nx,ny,nz), order='F')\n",
    "    return xx\n",
    "\n",
    "for i in range(len(train_idx)):\n",
    "    m = np.load('data_npy_100_100_11/inputs_rock_rates_locs_time/x_{}.npz'.format(train_idx[i]))\n",
    "    p = np.expand_dims(apply_mask(m['poro']), 0)[...,5:10] / 0.3\n",
    "    k = np.expand_dims(apply_mask(m['perm']), 0)[...,5:10] / 3.3\n",
    "    t = np.expand_dims(apply_mask(Tops), 0)[...,5:10]      / Tops.max()\n",
    "    xm[i] = np.concatenate([t, p, k], 0)\n",
    "\n",
    "    xw[i] = m['locs']\n",
    "    xc[i] = m['ctrl']\n",
    "    xt[i] = m['time']\n",
    "\n",
    "    dd = np.load('data_npy_100_100_11/outputs_pressure_saturation/y_{}.npz'.format(train_idx[i]))\n",
    "    prm = dd['pressure'][...,5:10]\n",
    "    sam = dd['saturation'][...,5:10]\n",
    "    yy[i,:,0] = np.expand_dims(prm, 0)\n",
    "    yy[i,:,1] = np.expand_dims(sam, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xm torch.Size([50, 3, 100, 100, 5])\n",
      "xw torch.Size([50, 10])\n",
      "xc torch.Size([50, 165])\n",
      "xt torch.Size([50, 33])\n",
      "yy torch.Size([50, 33, 2, 100, 100, 5])\n"
     ]
    }
   ],
   "source": [
    "x_m_tensor = torch.tensor(xm, dtype=torch.float32)\n",
    "x_w_tensor = torch.tensor(xw, dtype=torch.float32).reshape(train_size, -1)\n",
    "x_c_tensor = torch.tensor(xc, dtype=torch.float32).reshape(train_size, -1)\n",
    "x_t_tensor = torch.tensor(xt, dtype=torch.float32).reshape(train_size, -1)\n",
    "y_tensor = torch.tensor(yy, dtype=torch.float32)\n",
    "print('xm', x_m_tensor.shape)\n",
    "print('xw', x_w_tensor.shape)\n",
    "print('xc', x_c_tensor.shape)\n",
    "print('xt', x_t_tensor.shape)\n",
    "print('yy', y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_m_tensor[:-10], x_w_tensor[:-10], \n",
    "                              x_c_tensor[:-10], x_t_tensor[:-10], \n",
    "                              y_tensor[:-10])\n",
    "\n",
    "valid_dataset = TensorDataset(x_m_tensor[-10:], x_w_tensor[-10:], \n",
    "                              x_c_tensor[-10:], x_t_tensor[-10:], \n",
    "                              y_tensor[-10:])\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "validloader = DataLoader(valid_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.image import StructuralSimilarityIndexMeasure as SSIMLoss\n",
    "from torchmetrics.image import SpatialCorrelationCoefficient as SCCLoss\n",
    "from torchmetrics.image import SpectralDistortionIndex as SDILoss\n",
    "from torchmetrics.image import UniversalImageQualityIndex as UIQILoss\n",
    "from torchmetrics.image import VisualInformationFidelity as VIFLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.8, beta=0.7):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.ssim = SSIMLoss()\n",
    "        self.mse  = nn.MSELoss()\n",
    "        self.mae  = nn.L1Loss()\n",
    "        self.alpha = alpha\n",
    "        self.beta  = beta\n",
    "\n",
    "    def forward(self, true, pred):\n",
    "        ridge_loss = self.beta*self.mse(true, pred) + (1-self.beta)*self.mae(true, pred)\n",
    "        visual_loss = 1-self.ssim(true, pred)\n",
    "        total_loss = self.alpha*ridge_loss + (1-self.alpha)*visual_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters: 34,631,418\n"
     ]
    }
   ],
   "source": [
    "model = NeuralPix2Vid().to(device)\n",
    "print('# parameters: {:,}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = CustomLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Padding size should be less than the corresponding input dimension, but got: padding (5, 5) at dimension 2 of input [10, 33, 2, 50000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m yt \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m yh \u001b[38;5;241m=\u001b[39m model(xm, xw, xc, xt)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     17\u001b[0m epoch_train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mCustomLoss.forward\u001b[1;34m(self, true, pred)\u001b[0m\n\u001b[0;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mreshape(b,t,c,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m ridge_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmse(true, pred) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmae(true, pred)\n\u001b[1;32m---> 15\u001b[0m visual_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#total_loss = self.alpha*ridge_loss + (1-self.alpha)*visual_loss\u001b[39;00m\n\u001b[0;32m     17\u001b[0m true \u001b[38;5;241m=\u001b[39m true\u001b[38;5;241m.\u001b[39mreshape(b,t,c,h,w,d)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torchmetrics\\metric.py:303\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reduce_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torchmetrics\\metric.py:372\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    373\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torchmetrics\\metric.py:475\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[0;32m    468\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    469\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    470\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device corresponds to the device of the input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    474\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_on_cpu:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_list_states_to_cpu()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torchmetrics\\metric.py:465\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m         update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torchmetrics\\image\\ssim.py:131\u001b[0m, in \u001b[0;36mStructuralSimilarityIndexMeasure.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _ssim_check_inputs(preds, target)\n\u001b[1;32m--> 131\u001b[0m similarity_pack \u001b[38;5;241m=\u001b[39m \u001b[43m_ssim_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_full_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_contrast_sensitivity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(similarity_pack, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    145\u001b[0m     similarity, image \u001b[38;5;241m=\u001b[39m similarity_pack\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torchmetrics\\functional\\image\\ssim.py:137\u001b[0m, in \u001b[0;36m_ssim_update\u001b[1;34m(preds, target, gaussian_kernel, sigma, kernel_size, data_range, k1, k2, return_full_image, return_contrast_sensitivity)\u001b[0m\n\u001b[0;32m    135\u001b[0m         kernel \u001b[38;5;241m=\u001b[39m _gaussian_kernel_3d(channel, gauss_kernel_size, sigma, dtype, device)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_h\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflect\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m     target \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(target, (pad_w, pad_w, pad_h, pad_h), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gaussian_kernel:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Padding size should be less than the corresponding input dimension, but got: padding (5, 5) at dimension 2 of input [10, 33, 2, 50000]"
     ]
    }
   ],
   "source": [
    "epochs, monitor = 101, 10\n",
    "train_loss, valid_loss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    epoch_train_loss = []\n",
    "    model.train()\n",
    "    for i, (xm, xw, xc, xt, y) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        xm = xm.to(device)\n",
    "        xw = xw.to(device)\n",
    "        xc = xc.to(device)\n",
    "        xt = xt.to(device)\n",
    "        yt = y.to(device)\n",
    "        yh = model(xm, xw, xc, xt).to(device)\n",
    "        loss = criterion(yt, yh)\n",
    "        optimizer.step()\n",
    "        epoch_train_loss.append(loss.item())\n",
    "    train_loss.append(np.mean(epoch_train_loss))\n",
    "    # validation\n",
    "    model.eval()\n",
    "    epoch_valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        for i, (xmv, xwv, xcv, xtv, yv) in enumerate(validloader):\n",
    "            xmv = xmv.to(device)\n",
    "            xwv = xwv.to(device)\n",
    "            xcv = xcv.to(device)\n",
    "            xtv = xtv.to(device)\n",
    "            yv = yv.to(device)\n",
    "            yhv = model(xmv, xwv, xcv, xtv).to(device)\n",
    "            loss = criterion(yv, yhv)\n",
    "            epoch_valid_loss.append(loss.item())\n",
    "    valid_loss.append(np.mean(epoch_valid_loss))\n",
    "    # print\n",
    "    if epoch % monitor == 0:\n",
    "        print('Epoch: [{}/{}] | Loss: {:.4f} | Valid Loss: {:.4f}'.format(\n",
    "            epoch+1, epochs, train_loss[-1], valid_loss[-1]))\n",
    "\n",
    "torch.save(model.state_dict(), 'neuralpix2vid.pth')\n",
    "pd.DataFrame({'train': train_loss, 'valid': valid_loss}).to_csv('neuralpix2vid_losses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
