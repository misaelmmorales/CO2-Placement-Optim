{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well Placement and Control Optimization using a spatiotemporal proxy\n",
    "### Misael M. Morales - 2024\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.3.1+cu121 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): NVIDIA GeForce RTX 3080\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from scipy.io import savemat, loadmat\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import einsum\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from neuralop.models import *\n",
    "from transformers import Swinv2Config, Swinv2Model\n",
    "\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure as SSIMLoss\n",
    "from torchmetrics.image import RelativeAverageSpectralError as RASELoss\n",
    "from torchmetrics.image import SpatialCorrelationCoefficient as SCCLoss\n",
    "from torchmetrics.image import SpectralAngleMapper as SAMLoss\n",
    "from torchmetrics.image import SpectralDistortionIndex as SDILoss\n",
    "from torchmetrics.image import TotalVariation as TVmetrics\n",
    "from torchmetrics.image import UniversalImageQualityIndex as UIQILoss\n",
    "from torchmetrics.image import VisualInformationFidelity as VIFLoss\n",
    "\n",
    "from utils import check_torch\n",
    "device = check_torch()\n",
    "\n",
    "sec2year   = 365.25 * 24 * 60 * 60\n",
    "psi2pascal = 6894.76\n",
    "co2_rho    = 686.5266\n",
    "mega       = 1e6\n",
    "\n",
    "n_timesteps = 33\n",
    "nx, ny, nz  = 100, 100, 11\n",
    "\n",
    "indexMap = loadmat('data_100_100_11/G_cells_indexMap.mat', simplify_cells=True)['gci']\n",
    "Grid = np.zeros((nx,ny,nz)).flatten(order='F')\n",
    "Grid[indexMap] = 1\n",
    "Grid = Grid.reshape(nx,ny,nz, order='F')\n",
    "Tops = np.load('data_npy_100_100_11/tops_grid.npz')['tops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FTMiONet(nn.Module):\n",
    "    def __init__(self, hidden_1:int=16, hidden_2:int=32, hidden_3:int=64):\n",
    "        super(FTMiONet, self).__init__()\n",
    "        self.hidden_1 = hidden_1\n",
    "        self.hidden_2 = hidden_2\n",
    "        self.hidden_3 = hidden_3\n",
    "\n",
    "        self.conv1 = nn.Conv3d(2, hidden_1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(hidden_1, hidden_2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(hidden_2, hidden_3, kernel_size=3, padding=1)\n",
    "        self.norm1 = nn.InstanceNorm3d(hidden_1)\n",
    "        self.norm2 = nn.InstanceNorm3d(hidden_2)\n",
    "        self.norm3 = nn.InstanceNorm3d(hidden_3)\n",
    "        self.pool = nn.MaxPool3d((1,1,2))\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        self.vitm = Swinv2Model(Swinv2Config(image_size=100, num_channels=hidden_3,\n",
    "                                             embed_dim=96, num_heads=[2,4,8,16],\n",
    "                                             output_attention=True,\n",
    "                                             output_hidden_states=True))\n",
    "\n",
    "        self.vitg = Swinv2Model(Swinv2Config(image_size=100, num_channels=hidden_3,\n",
    "                                             embed_dim=96, num_heads=[2,4,8,16],\n",
    "                                             output_attention=True,\n",
    "                                             output_hidden_states=True))\n",
    "\n",
    "        self.tel1 = nn.TransformerEncoderLayer(d_model=10, nhead=2, dim_feedforward=1024, activation='gelu', batch_first=True)\n",
    "        self.tel2 = nn.TransformerEncoderLayer(d_model=160, nhead=8, dim_feedforward=1024, activation='gelu', batch_first=True)\n",
    "        self.tel3 = nn.TransformerEncoderLayer(d_model=32, nhead=8, dim_feedforward=1024, activation='gelu', batch_first=True)\n",
    "\n",
    "        self.trf1 = nn.TransformerEncoder(self.tel1, num_layers=4)\n",
    "        self.trf2 = nn.TransformerEncoder(self.tel2, num_layers=4)\n",
    "        self.trf3 = nn.TransformerEncoder(self.tel3, num_layers=4)\n",
    "\n",
    "        self.fno = FNO(n_modes=(1,4), n_layers=2, norm='instance_norm',\n",
    "                       in_channels=2, \n",
    "                       lifting_channels=hidden_1, \n",
    "                       hidden_channels=hidden_3, \n",
    "                       projection_channels=hidden_1,\n",
    "                       out_channels=2)\n",
    "        self.lift = nn.Linear(1920, 29128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xm, xg, xw, xc, xt = x\n",
    "\n",
    "        zm = self.pool(self.norm1(self.gelu(self.conv1(xm))))\n",
    "        zm = self.pool(self.norm2(self.gelu(self.conv2(zm))))\n",
    "        zm = self.pool(self.norm3(self.gelu(self.conv3(zm)))).squeeze()\n",
    "        mv = self.vitm(zm)\n",
    "        zm = mv['reshaped_hidden_states'][-1].reshape(zm.shape[0], -1)\n",
    "\n",
    "        zg = self.pool(self.norm1(self.gelu(self.conv1(xg))))\n",
    "        zg = self.pool(self.norm2(self.gelu(self.conv2(zg))))\n",
    "        zg = self.pool(self.norm3(self.gelu(self.conv3(zg)))).squeeze()\n",
    "        gv = self.vitg(zg)\n",
    "        zg = gv['reshaped_hidden_states'][-1].reshape(zg.shape[0], -1)\n",
    "\n",
    "        zw = xw.view(xw.shape[0], -1)\n",
    "        zw = self.trf1(zw)\n",
    "\n",
    "        zc = xc.view(xc.shape[0], -1)\n",
    "        zc = self.trf2(zc)\n",
    "\n",
    "        zt = xt.view(xt.shape[0], -1)\n",
    "        zt = self.trf3(zt)\n",
    "\n",
    "        mg = torch.einsum('bp,bp->bp', zm, zg)\n",
    "        wc = torch.einsum('bw,bc->bwc', zw, zc)\n",
    "        zb = torch.einsum('bp,bwc->bwcp', mg, wc)\n",
    "        zb = zb.reshape(zb.shape[0], 2, 5, 5, 32, 32, 384)\n",
    "        zb = torch.einsum('blwwttp,blwwttp->blwtp', zb, zb)\n",
    "        merge = torch.einsum('blwtp,bt->blwtp', zb, zt)\n",
    "        merge = merge.permute(0,1,3,2,4).reshape(merge.shape[0], 2, 32, -1)\n",
    "        zy = self.fno(merge)\n",
    "        yy = self.lift(zy)\n",
    "        \n",
    "        return yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder:str='data_npy_100_100_11'):\n",
    "        self.data_folder = data_folder\n",
    "        \n",
    "        self.x_folder = os.path.join(data_folder, 'inputs_rock_rates_locs_time')\n",
    "        self.y_folder = os.path.join(data_folder, 'outputs_masked_pressure_saturation')\n",
    "\n",
    "        self.x_file_list = os.listdir(self.x_folder)\n",
    "        self.y_file_list = os.listdir(self.y_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x  = np.load(os.path.join(self.x_folder, self.x_file_list[idx]))\n",
    "        y  = np.load(os.path.join(self.y_folder, self.y_file_list[idx]))\n",
    "\n",
    "        xg = np.concatenate([np.expand_dims(Tops/(3000), 0), \n",
    "                             np.expand_dims(Grid, 0)], \n",
    "                             axis=0)\n",
    "\n",
    "        xm = np.concatenate([np.expand_dims(x['poro']/(0.3),0), \n",
    "                             np.expand_dims(x['perm']/(3.3),0)], \n",
    "                             axis=0)\n",
    "        \n",
    "        xw = x['locs']           / (100)\n",
    "        xc = x['ctrl'][1:]       * co2_rho*sec2year/mega/1e3/(25)\n",
    "        xt = x['time'][1:]       / sec2year / (100)\n",
    "        yp = y['pressure'][2:]   / psi2pascal / (1e4)\n",
    "        ys = y['saturation'][2:] / 0.8\n",
    "        yy = np.concatenate([np.expand_dims(yp,0), np.expand_dims(ys,0)], axis=0)\n",
    "\n",
    "        xm = torch.tensor(xm, dtype=torch.float32, device=device)\n",
    "        xg = torch.tensor(xg, dtype=torch.float32, device=device)\n",
    "        xw = torch.tensor(xw, dtype=torch.float32, device=device)\n",
    "        xc = torch.tensor(xc, dtype=torch.float32, device=device)\n",
    "        xt = torch.tensor(xt, dtype=torch.float32, device=device)\n",
    "        yy = torch.tensor(yy, dtype=torch.float32, device=device)\n",
    "\n",
    "        return (xm, xg, xw, xc, xt), yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.85, beta=0.20):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.mae = nn.L1Loss()\n",
    "        self.ssim = SSIMLoss()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, true, pred):\n",
    "        mse_loss = self.mse(true, pred)\n",
    "        mae_loss = self.mae(true, pred)\n",
    "        ssim_loss = 1 - self.ssim(true, pred)\n",
    "        return self.alpha(self.beta*mse_loss + (1-self.beta)*mae_loss) + (1-self.alpah)*ssim_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Parameters: 114,008,580\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset()\n",
    "trainset, testset  = random_split(dataset, [1172, 100])\n",
    "trainset, validset = random_split(trainset, [1000, 172])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "validloader = DataLoader(validset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = FTMiONet().to(device)\n",
    "print('# Parameters: {:,}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv('MiONet_losses.csv')\n",
    "\n",
    "def plot_loss(history, figsize=(8,4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(history.index, history['train'], ls='-', label='Train')\n",
    "    plt.plot(history.index, history['valid'], ls='-', label='Valid')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "    plt.legend(); plt.grid(True, which='both')\n",
    "    plt.tight_layout(); plt.savefig('loss.png'); plt.show()\n",
    "    return None\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
