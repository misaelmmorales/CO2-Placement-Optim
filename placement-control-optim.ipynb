{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well Placement and Control Optimization using a spatiotemporal proxy\n",
    "### Misael M. Morales - 2024\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.4.0+cu121 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): NVIDIA GeForce RTX 3090\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from scipy.io import savemat, loadmat\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import einsum\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from neuralop.models import *\n",
    "from neuralop.layers import *\n",
    "from transformers import Swinv2Config, Swinv2Model\n",
    "\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure as SSIMLoss\n",
    "from torchmetrics.image import RelativeAverageSpectralError as RASELoss\n",
    "from torchmetrics.image import SpatialCorrelationCoefficient as SCCLoss\n",
    "from torchmetrics.image import SpectralAngleMapper as SAMLoss\n",
    "from torchmetrics.image import SpectralDistortionIndex as SDILoss\n",
    "from torchmetrics.image import TotalVariation as TVmetrics\n",
    "from torchmetrics.image import UniversalImageQualityIndex as UIQILoss\n",
    "from torchmetrics.image import VisualInformationFidelity as VIFLoss\n",
    "\n",
    "from utils import check_torch\n",
    "device = check_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec2year   = 365.25 * 24 * 60 * 60\n",
    "psi2pascal = 6894.76\n",
    "co2_rho    = 686.5266\n",
    "mega       = 1e6\n",
    "\n",
    "n_timesteps = 33\n",
    "nx, ny, nz, nz_short  = 100, 100, 11, 5\n",
    "\n",
    "indexMap = loadmat('data_100_100_11/G_cells_indexMap.mat', simplify_cells=True)['gci']\n",
    "Grid = np.zeros((nx,ny,nz)).flatten(order='F')\n",
    "Grid[indexMap] = 1\n",
    "Grid = Grid.reshape(nx,ny,nz, order='F')\n",
    "Tops = np.load('data_npy_100_100_11/tops_grid.npz')['tops']\n",
    "print('Grid: {} | Tops: {}'.format(Grid.shape, Tops.shape))\n",
    "\n",
    "Grid_short = Grid[:,:,5:10]\n",
    "Grid_ext = np.repeat(np.expand_dims(Grid, 0), 33, axis=0)\n",
    "Grid_short_ext = np.repeat(np.expand_dims(Grid_short, 0), 33, axis=0)\n",
    "print('Grid_ext: {} | Grid_short_ext: {}'.format(Grid_ext.shape, Grid_short_ext.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(range(1272), size=5, replace=False)\n",
    "test_idx  = np.setdiff1d(range(1272), train_idx)\n",
    "\n",
    "xm = np.zeros((len(train_idx), 3, 100,100,5))\n",
    "xw = np.zeros((len(train_idx), 2, 5))\n",
    "xc = np.zeros((len(train_idx), n_timesteps, 5))\n",
    "xt = np.zeros((len(train_idx), n_timesteps, 1))\n",
    "yy = np.zeros((len(train_idx), 33, 2, 100,100,5))\n",
    "\n",
    "def apply_mask(x, imap=indexMap, mask_value=0.0):\n",
    "    xx = mask_value*np.ones((nx,ny,nz)).flatten(order='F')\n",
    "    xx[imap] = x.flatten(order='F')[imap]\n",
    "    xx = xx.reshape((nx,ny,nz), order='F')\n",
    "    return xx\n",
    "\n",
    "for i in range(len(train_idx)):\n",
    "    m = np.load('data_npy_100_100_11/inputs_rock_rates_locs_time/x_{}.npz'.format(train_idx[i]))\n",
    "    p = np.expand_dims(apply_mask(m['poro']), 0)[...,5:10] / 0.3\n",
    "    k = np.expand_dims(apply_mask(m['perm']), 0)[...,5:10] / 3.3\n",
    "    t = np.expand_dims(apply_mask(Tops), 0)[...,5:10]      / Tops.max()\n",
    "    xm[i] = np.concatenate([t, p, k], 0)\n",
    "\n",
    "    xw[i] = m['locs']\n",
    "    xc[i] = m['ctrl']\n",
    "    xt[i] = m['time']\n",
    "\n",
    "    dd = np.load('data_npy_100_100_11/outputs_pressure_saturation/y_{}.npz'.format(train_idx[i]))\n",
    "    prm = dd['pressure'][...,5:10]\n",
    "    sam = dd['saturation'][...,5:10]\n",
    "    yy[i,:,0] = np.expand_dims(prm, 0)\n",
    "    yy[i,:,1] = np.expand_dims(sam, 0)\n",
    "\n",
    "inj_locs  = np.zeros((len(train_idx), 1, 100,100,5))\n",
    "inj_rates = np.zeros((len(train_idx), 1, 100,100,5))\n",
    "inj_times = np.zeros((len(train_idx), 1, 100,100,5))\n",
    "for i in range(len(train_idx)):\n",
    "    inj_locs[i, 0, xw[i][0,:].astype(int), xw[i][1,:].astype(int), :] = 1\n",
    "    inj_rates[i] = np.expand_dims(np.repeat(np.expand_dims(np.concatenate([np.zeros((1,100)),\n",
    "                                      np.repeat(np.repeat(xc[1],20,axis=-1),3,axis=0)],\n",
    "                                      axis=0), -1), 5, axis=-1),0)\n",
    "    inj_times[i] = np.repeat(np.expand_dims(np.expand_dims(np.concatenate([np.zeros((1,100)),\n",
    "                                      np.repeat(np.repeat(xt[0],3,axis=0),100,axis=1)],axis=0),0),-1), 5, axis=-1)\n",
    "\n",
    "xx = np.concatenate([xm, inj_locs, inj_rates, inj_times], 1)\n",
    "\n",
    "print('xx', xx.shape)\n",
    "print('yy', yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fno = FNO(n_modes=(4,4,2), in_channels=6, out_channels=1, \n",
    "          lifting_channels=64, hidden_channels=256, projection_channels=64,\n",
    "          n_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fno(torch.Tensor(xx)).detach().numpy()\n",
    "print(temp.shape)\n",
    "\n",
    "fig, axs = plt.subplots(5,5, figsize=(12,5), sharex=True, sharey=True)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(temp[i,0,:,:,j], cmap='jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sconv = spectral_convolution.SpectralConv3d(in_channels=2, out_channels=4, n_modes=(4,4,1))\n",
    "y = sconv(m).detach().numpy()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fno = FNO(in_channels=2, out_channels=4, n_modes=(4,4,1), \n",
    "          lifting_channels=256, hidden_channels=1024, projection_channels=256,\n",
    "          n_layers=4, )\n",
    "\n",
    "f = fno(m).detach().numpy()\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 11, figsize=(15,5), sharex=True, sharey=True)\n",
    "for i in range(2):\n",
    "    for j in range(11):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(m[0,i,:,:,j].detach().numpy(), 'jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 11, figsize=(15,5), sharex=True, sharey=True)\n",
    "for i in range(4):\n",
    "    for j in range(11):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(y[0,i,:,:,j], 'jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 11, figsize=(15,5), sharex=True, sharey=True)\n",
    "for i in range(4):\n",
    "    for j in range(11):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(f[0,i,:,:,j], 'jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VivitConfig, VivitModel, SwinConfig, SwinModel, ViTMAEConfig, ViTMAEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = ViTMAEModel(ViTMAEConfig(image_size=100, num_channels=11,\n",
    "                               patch_size=9,\n",
    "                               num_hidden_layers=12, num_attention_heads=8, \n",
    "                               intermediate_size=3072, hidden_size=1024,\n",
    "                               output_attentions=True, return_dict=True))\n",
    "\n",
    "y = vit(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.keys())\n",
    "\n",
    "y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwise_separable_conv(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=3, padding=1, groups=nin)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FTMiONet(nn.Module):\n",
    "    def __init__(self, hidden_1:int=16, hidden_2:int=32, hidden_3:int=64):\n",
    "        super(FTMiONet, self).__init__()\n",
    "        self.hidden_1 = hidden_1\n",
    "        self.hidden_2 = hidden_2\n",
    "        self.hidden_3 = hidden_3\n",
    "\n",
    "        self.conv1 = nn.Conv3d(2, hidden_1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(hidden_1, hidden_2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(hidden_2, hidden_3, kernel_size=3, padding=1)\n",
    "        self.norm1 = nn.InstanceNorm3d(hidden_1)\n",
    "        self.norm2 = nn.InstanceNorm3d(hidden_2)\n",
    "        self.norm3 = nn.InstanceNorm3d(hidden_3)\n",
    "        self.pool = nn.MaxPool3d((1,1,2))\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        self.vitm = Swinv2Model(Swinv2Config(image_size=100, num_channels=hidden_3,\n",
    "                                             embed_dim=96, num_heads=[2,4,8,16],\n",
    "                                             output_attention=True,\n",
    "                                             output_hidden_states=True))\n",
    "\n",
    "        self.vitg = Swinv2Model(Swinv2Config(image_size=100, num_channels=hidden_3,\n",
    "                                             embed_dim=96, num_heads=[2,4,8,16],\n",
    "                                             output_attention=True,\n",
    "                                             output_hidden_states=True))\n",
    "\n",
    "        self.tel1 = nn.TransformerEncoderLayer(d_model=10, nhead=2, dim_feedforward=1024, activation='gelu', batch_first=True)\n",
    "        self.tel2 = nn.TransformerEncoderLayer(d_model=160, nhead=8, dim_feedforward=1024, activation='gelu', batch_first=True)\n",
    "        self.tel3 = nn.TransformerEncoderLayer(d_model=32, nhead=8, dim_feedforward=1024, activation='gelu', batch_first=True)\n",
    "\n",
    "        self.trf1 = nn.TransformerEncoder(self.tel1, num_layers=4)\n",
    "        self.trf2 = nn.TransformerEncoder(self.tel2, num_layers=4)\n",
    "        self.trf3 = nn.TransformerEncoder(self.tel3, num_layers=4)\n",
    "\n",
    "        self.fno = FNO(n_modes=(1,4), n_layers=2, norm='instance_norm',\n",
    "                       in_channels=2, \n",
    "                       lifting_channels=hidden_1, \n",
    "                       hidden_channels=hidden_3, \n",
    "                       projection_channels=hidden_1,\n",
    "                       out_channels=2)\n",
    "        self.lift = nn.Linear(1920, 29128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xm, xg, xw, xc, xt = x\n",
    "\n",
    "        zm = self.pool(self.norm1(self.gelu(self.conv1(xm))))\n",
    "        zm = self.pool(self.norm2(self.gelu(self.conv2(zm))))\n",
    "        zm = self.pool(self.norm3(self.gelu(self.conv3(zm)))).squeeze()\n",
    "        mv = self.vitm(zm)\n",
    "        zm = mv['reshaped_hidden_states'][-1].reshape(zm.shape[0], -1)\n",
    "\n",
    "        zg = self.pool(self.norm1(self.gelu(self.conv1(xg))))\n",
    "        zg = self.pool(self.norm2(self.gelu(self.conv2(zg))))\n",
    "        zg = self.pool(self.norm3(self.gelu(self.conv3(zg)))).squeeze()\n",
    "        gv = self.vitg(zg)\n",
    "        zg = gv['reshaped_hidden_states'][-1].reshape(zg.shape[0], -1)\n",
    "\n",
    "        zw = xw.view(xw.shape[0], -1)\n",
    "        zw = self.trf1(zw)\n",
    "\n",
    "        zc = xc.view(xc.shape[0], -1)\n",
    "        zc = self.trf2(zc)\n",
    "\n",
    "        zt = xt.view(xt.shape[0], -1)\n",
    "        zt = self.trf3(zt)\n",
    "\n",
    "        mg = torch.einsum('bp,bp->bp', zm, zg)\n",
    "        wc = torch.einsum('bw,bc->bwc', zw, zc)\n",
    "        zb = torch.einsum('bp,bwc->bwcp', mg, wc)\n",
    "        zb = zb.reshape(zb.shape[0], 2, 5, 5, 32, 32, 384)\n",
    "        zb = torch.einsum('blwwttp,blwwttp->blwtp', zb, zb)\n",
    "        merge = torch.einsum('blwtp,bt->blwtp', zb, zt)\n",
    "        merge = merge.permute(0,1,3,2,4).reshape(merge.shape[0], 2, 32, -1)\n",
    "        zy = self.fno(merge)\n",
    "        yy = self.lift(zy)\n",
    "        \n",
    "        return yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder:str='data_npy_100_100_11'):\n",
    "        self.data_folder = data_folder\n",
    "        \n",
    "        self.x_folder = os.path.join(data_folder, 'inputs_rock_rates_locs_time')\n",
    "        self.y_folder = os.path.join(data_folder, 'outputs_masked_pressure_saturation')\n",
    "\n",
    "        self.x_file_list = os.listdir(self.x_folder)\n",
    "        self.y_file_list = os.listdir(self.y_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x  = np.load(os.path.join(self.x_folder, self.x_file_list[idx]))\n",
    "        y  = np.load(os.path.join(self.y_folder, self.y_file_list[idx]))\n",
    "\n",
    "        xg = np.concatenate([np.expand_dims(Tops/(3000), 0), \n",
    "                             np.expand_dims(Grid, 0)], \n",
    "                             axis=0)\n",
    "\n",
    "        xm = np.concatenate([np.expand_dims(x['poro']/(0.3),0), \n",
    "                             np.expand_dims(x['perm']/(3.3),0)], \n",
    "                             axis=0)\n",
    "        \n",
    "        xw = x['locs']           / (100)\n",
    "        xc = x['ctrl'][1:]       * co2_rho*sec2year/mega/1e3/(25)\n",
    "        xt = x['time'][1:]       / sec2year / (100)\n",
    "        yp = y['pressure'][2:]   / psi2pascal / (1e4)\n",
    "        ys = y['saturation'][2:] / 0.8\n",
    "        yy = np.concatenate([np.expand_dims(yp,0), np.expand_dims(ys,0)], axis=0)\n",
    "\n",
    "        xm = torch.tensor(xm, dtype=torch.float32, device=device)\n",
    "        xg = torch.tensor(xg, dtype=torch.float32, device=device)\n",
    "        xw = torch.tensor(xw, dtype=torch.float32, device=device)\n",
    "        xc = torch.tensor(xc, dtype=torch.float32, device=device)\n",
    "        xt = torch.tensor(xt, dtype=torch.float32, device=device)\n",
    "        yy = torch.tensor(yy, dtype=torch.float32, device=device)\n",
    "\n",
    "        return (xm, xg, xw, xc, xt), yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiONet(nn.Module):\n",
    "    def __init__(self, hidden_channels=16, output_channels=32):\n",
    "        super(MiONet, self).__init__()\n",
    "        self.hidden = hidden_channels\n",
    "        self.output = output_channels\n",
    "\n",
    "        self.conv1 = nn.Conv3d(2, self.hidden, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(self.hidden, self.output, kernel_size=3, padding=1)\n",
    "        self.norm1 = nn.BatchNorm3d(self.hidden)\n",
    "        self.norm2 = nn.BatchNorm3d(self.output)\n",
    "        self.pool  = nn.MaxPool3d(2)\n",
    "        self.gelu  = nn.GELU()\n",
    "\n",
    "        self.linW1 = nn.Linear(5, self.hidden)\n",
    "        self.linW2 = nn.Linear(self.hidden, self.output)\n",
    "        self.bnW1  = nn.BatchNorm1d(self.hidden//8)\n",
    "        self.bnW2  = nn.BatchNorm1d(self.output//16)\n",
    "\n",
    "        self.lstmC1 = nn.LSTM(5, self.hidden, num_layers=1, batch_first=True)\n",
    "        self.lstmC2 = nn.LSTM(self.hidden, self.output, num_layers=1, batch_first=True)\n",
    "\n",
    "        self.lmstT1 = nn.LSTM(1, self.hidden, num_layers=1, batch_first=True)\n",
    "        self.lmstT2 = nn.LSTM(self.hidden, self.output, num_layers=1, batch_first=True)\n",
    "\n",
    "        self.linY1 = nn.Linear(1250, 10000)\n",
    "        self.linY2 = nn.Linear(10000, 29128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xm, xg, xw, xc, xt = x\n",
    "\n",
    "        zm = self.gelu(self.pool(self.norm1(self.conv1(xm))))\n",
    "        zm = self.gelu(self.pool(self.norm2(self.conv2(zm))))\n",
    "        zm = zm.view(zm.shape[0], self.output, -1)\n",
    "\n",
    "        zg = self.gelu(self.pool(self.norm1(self.conv1(xg))))\n",
    "        zg = self.gelu(self.pool(self.norm2(self.conv2(zg))))\n",
    "        zg = zg.view(zg.shape[0], self.output, -1)\n",
    "\n",
    "        zw = self.gelu(self.bnW1(self.linW1(xw)))\n",
    "        zw = self.gelu(self.bnW2(self.linW2(zw)))\n",
    "\n",
    "        zc, _ = self.lstmC1(xc)\n",
    "        zc, _ = self.lstmC2(zc)\n",
    "\n",
    "        zt, _ = self.lmstT1(xt)\n",
    "        zt, _ = self.lmstT2(zt)\n",
    "\n",
    "        mg = torch.einsum('bcp,bcp->bcp', zm, zg)\n",
    "        wc = torch.einsum('blc,btc->btlc', zw, zc)\n",
    "        branch = torch.einsum('bcp,btlc->btpl', mg, wc)\n",
    "        merge  = torch.einsum('btpl,btc->btlp', branch, zt)\n",
    "\n",
    "        yy = self.gelu(self.linY1(merge))\n",
    "        yy = self.linY2(yy)\n",
    "\n",
    "        return yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.85, beta=0.20):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.mae = nn.L1Loss()\n",
    "        self.ssim = SSIMLoss()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, true, pred):\n",
    "        mse_loss = self.mse(true, pred)\n",
    "        mae_loss = self.mae(true, pred)\n",
    "        ssim_loss = 1 - self.ssim(true, pred)\n",
    "        return self.alpha(self.beta*mse_loss + (1-self.beta)*mae_loss) + (1-self.alpah)*ssim_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "trainset, testset  = random_split(dataset, [1172, 100])\n",
    "trainset, validset = random_split(trainset, [1000, 172])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "validloader = DataLoader(validset, batch_size=32, shuffle=False)\n",
    "testloader  = DataLoader(testset,  batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FTMiONet().to(device)\n",
    "model.load_state_dict(torch.load('trained_models/FTMiONet.pth'))\n",
    "print('# Parameters: {:,}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x,y) in enumerate(testloader):\n",
    "    yh = model(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid_ext = np.repeat(np.expand_dims(Grid, 0), 32, axis=0)\n",
    "print('Extended Grid: {}'.format(Grid_ext.shape))\n",
    "\n",
    "timesteps = 100*x[-1][0].squeeze().detach().cpu().numpy()\n",
    "print(timesteps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spred = np.zeros((32,100,100,11)).reshape(32, -1, order='F')\n",
    "maskt = Grid_ext.reshape(32, -1, order='F')\n",
    "\n",
    "spred[:,indexMap] = yh[0,0].detach().cpu().numpy()\n",
    "spred = np.ma.masked_where(maskt==0, spred)\n",
    "spred = spred.reshape(32,100,100,11, order='F')\n",
    "\n",
    "fig, axs = plt.subplots(4, 8, figsize=(16,8), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.imshow(spred[i,:,:,7], cmap='jet')\n",
    "    ax.set(title='t={:.2f}'.format(timesteps[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strue = np.zeros((32,100,100,11)).reshape(32, -1, order='F')\n",
    "maskt = Grid_ext.reshape(32, -1, order='F')\n",
    "\n",
    "strue[:,indexMap] = y[0,0].detach().cpu().numpy()\n",
    "strue = np.ma.masked_where(maskt==0, strue)\n",
    "strue = strue.reshape(32,100,100,11, order='F')\n",
    "\n",
    "fig, axs = plt.subplots(4, 8, figsize=(16,8), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.imshow(strue[i,:,:,5], cmap='jet', vmin=0.25, vmax=2.50)\n",
    "    ax.set(title='t={:.2f}'.format(timesteps[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv('MiONet_losses.csv')\n",
    "\n",
    "def plot_loss(history, figsize=(8,4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(history.index, history['train'], ls='-', label='Train')\n",
    "    plt.plot(history.index, history['valid'], ls='-', label='Valid')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "    plt.legend(); plt.grid(True, which='both')\n",
    "    plt.tight_layout(); plt.savefig('loss.png'); plt.show()\n",
    "    return None\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
