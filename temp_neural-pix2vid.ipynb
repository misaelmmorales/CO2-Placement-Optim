{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79f82c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "-------------------------- VERSION INFO --------------------------\n",
      "TF version: 2.15.0 | # Device(s) available: 2\n",
      "TF Built with CUDA? True | CUDA: 12.0 | cuDNN: 8\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU') \n",
      " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import einops\n",
    "import tensorflow as tf\n",
    "from tensorflow import einsum\n",
    "from tensorflow.image import ssim as tf_ssim, psnr as tf_psnr\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.optimizers import AdamW\n",
    "from keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "def check_tf_gpu():\n",
    "    sys_info = tf.sysconfig.get_build_info()\n",
    "    version, cuda, cudnn = tf.__version__, sys_info[\"cuda_version\"], sys_info[\"cudnn_version\"]\n",
    "    count = len(tf.config.experimental.list_physical_devices())\n",
    "    name  = [device.name for device in tf.config.experimental.list_physical_devices('GPU')]\n",
    "    print('-'*66)\n",
    "    print('-'*26, 'VERSION INFO', '-'*26)\n",
    "    print('TF version: {} | # Device(s) available: {}'.format(version, count))\n",
    "    print('TF Built with CUDA? {} | CUDA: {} | cuDNN: {}'.format(tf.test.is_built_with_cuda(), cuda, cudnn))\n",
    "    print(tf.config.list_physical_devices()[0],'\\n', tf.config.list_physical_devices()[1])\n",
    "    print('-'*66+'\\n')\n",
    "    return None\n",
    "\n",
    "check_tf_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec2year   = 365.25 * 24 * 60 * 60\n",
    "psi2pascal = 6894.76\n",
    "co2_rho    = 686.5266\n",
    "mega       = 1e6\n",
    "\n",
    "n_timesteps = 33\n",
    "nx, ny, nz, nz_short  = 100, 100, 11, 5\n",
    "\n",
    "indexMap = loadmat('data_100_100_11/G_cells_indexMap.mat', simplify_cells=True)['gci']\n",
    "Grid = np.zeros((nx,ny,nz)).flatten(order='F')\n",
    "Grid[indexMap] = 1\n",
    "Grid = Grid.reshape(nx,ny,nz, order='F')\n",
    "Tops = np.load('data_npy_100_100_11/tops_grid.npz')['tops']\n",
    "print('Grid: {} | Tops: {}'.format(Grid.shape, Tops.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "  def __init__(self, filters, kernel_size, padding):\n",
    "    \"\"\"\n",
    "      A sequence of convolutional layers that first apply the convolution operation over the\n",
    "      spatial dimensions, and then the temporal dimension. \n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.seq = keras.Sequential([  \n",
    "        # Spatial decomposition\n",
    "        layers.Conv3D(filters=filters,\n",
    "                      kernel_size=(1, kernel_size[1], kernel_size[2]),\n",
    "                      padding=padding),\n",
    "        # Temporal decomposition\n",
    "        layers.Conv3D(filters=filters, \n",
    "                      kernel_size=(kernel_size[0], 1, 1),\n",
    "                      padding=padding)\n",
    "        ])\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    K.clear_session()\n",
    "    inp_xm = Input(shape=(29128, 2))\n",
    "    inp_xg = Input(shape=(29128, 2))\n",
    "    inp_xw = Input(shape=(2, 5))\n",
    "    inp_xc = Input(shape=(None, 5))\n",
    "    inp_xt = Input(shape=(None, 1))\n",
    "    inputs = [inp_xm, inp_xg, inp_xw, inp_xc, inp_xt]\n",
    "\n",
    "    def conv_block(inp, filt):\n",
    "        _ = Masking(mask_value=0.)(inp)\n",
    "        _ = Conv2Plus1D(filters=filt, kernel_size=(3,3,3), padding='same')(_)\n",
    "        _ = GroupNormalization(groups=-1)(_)\n",
    "        _ = Activation('gelu')(_)\n",
    "        _ = Conv2Plus1D(filters=filt, kernel_size=(3,3,3), padding='same')(_)\n",
    "        _ = GroupNormalization(groups=-1)(_)\n",
    "        _ = Activation('gelu')(_)\n",
    "        _ = MaxPooling3D((2,2,1))(_)\n",
    "        return _\n",
    "    \n",
    "    def triple_dense_block(inp, units):\n",
    "        def dense_block(inp, units):\n",
    "            _ = Dense(units)(inp)\n",
    "            _ = GroupNormalization(groups=-1)(_)\n",
    "            _ = Activation('gelu')(_)\n",
    "            return _\n",
    "        _ = dense_block(inp, units)\n",
    "        _ = dense_block(_, units)\n",
    "        _ = dense_block(_, units)\n",
    "        return _\n",
    "    \n",
    "    def recc_block(inp, units):\n",
    "        _ = LSTM(units, return_sequences=True)(inp)\n",
    "        _ = LayerNormalization()(_)\n",
    "        _ = Activation('gelu')(_)\n",
    "        _ = LSTM(units, return_sequences=True)(_)\n",
    "        _ = LayerNormalization()(_)\n",
    "        _ = Activation('gelu')(_)\n",
    "        return _\n",
    "    \n",
    "    def decon_block(inp, filt):\n",
    "        _ = TimeDistributed(Conv2Plus1D(filters=filt, kernel_size=(3,3,3), padding='same'))(inp)\n",
    "        _ = GroupNormalization(groups=-1)(_)\n",
    "        _ = Activation('gelu')(_)\n",
    "        _ = TimeDistributed(Conv2Plus1D(filters=filt, kernel_size=(3,3,3), padding='same'))(_)\n",
    "        _ = GroupNormalization(groups=-1)(_)\n",
    "        _ = Activation('gelu')(_)\n",
    "        _ = TimeDistributed(Conv3DTranspose(filt//4, 3, strides=(2,2,1), padding='same'))(_)\n",
    "        return _\n",
    "    \n",
    "    # xm = conv_block(inp_xm, 64)\n",
    "    # xm = conv_block(xm, 128)\n",
    "\n",
    "    # xg = conv_block(inp_xg, 64)\n",
    "    # xg = conv_block(xg, 128)\n",
    "\n",
    "    xm = triple_dense_block(inp_xm, 100)\n",
    "    xg = triple_dense_block(inp_xg, 100)\n",
    "\n",
    "    xw = recc_block(inp_xw, 50)\n",
    "    xw = triple_dense_block(xw, 100)\n",
    "\n",
    "    xc = recc_block(inp_xc, 50)\n",
    "    xc = triple_dense_block(xc, 100)\n",
    "\n",
    "    xt = recc_block(inp_xt, 50)\n",
    "    xt = triple_dense_block(xt, 100)\n",
    "\n",
    "    mg = einsum('bpc, bpc -> bpc', xm, xg)\n",
    "    wc = einsum('blc, btc -> btlc', xw, xc)\n",
    "\n",
    "    branch = einsum('bpc, btlc -> btpc', mg, wc)\n",
    "    trunk  = einsum('btpc, btc -> btpc', branch, xt)\n",
    "\n",
    "    x = Dense(2)(trunk)\n",
    "    \n",
    "\n",
    "    # x = decon_block(trunk, 128)\n",
    "    # x = decon_block(x, 64)\n",
    "    # x = TimeDistributed(Conv2Plus1D(filters=2, kernel_size=(3,3,3), padding='same'))(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(true, pred, alpha=0.66, beta=0.33):\n",
    "    ssim_loss = tf.reduce_mean(1.0 - tf_ssim(true, pred, max_val=1.0))\n",
    "    mse_loss  = MeanSquaredError()(true, pred)\n",
    "    mae_loss  = MeanAbsoluteError()(true, pred)\n",
    "    ridge_loss = beta*mae_loss + (1-beta)*mse_loss\n",
    "    return alpha*ssim_loss + (1-alpha)*ridge_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "print('# Parameters: {:,}'.format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c226f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(range(1272), size=500, replace=False)\n",
    "test_idx  = np.setdiff1d(range(1272), train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xm = np.zeros((len(train_idx), nx, ny, nz_short, 2))\n",
    "# xg = np.zeros((len(train_idx), nx, ny, nz_short, 2))\n",
    "xm = np.zeros((len(train_idx), 29128, 2))\n",
    "xg = np.zeros((len(train_idx), 29128, 2))\n",
    "xw = np.zeros((len(train_idx), 2, 5))\n",
    "xc = np.zeros((len(train_idx), n_timesteps, 5))\n",
    "xt = np.zeros((len(train_idx), n_timesteps, 1))\n",
    "yy = np.zeros((len(train_idx), 33, 29128, 2))\n",
    "Grid_ext = np.repeat(np.expand_dims(Grid, 0), 33, axis=0)\n",
    "\n",
    "def apply_mask(x, imap, mask_value=0.0):\n",
    "    xx = mask_value*np.ones((nx,ny,nz)).flatten(order='F')\n",
    "    xx[imap] = x.flatten(order='F')[imap]\n",
    "    xx = xx.reshape((nx,ny,nz), order='F')[...,5:10]\n",
    "    return xx\n",
    "\n",
    "for i in range(len(train_idx)):\n",
    "    # xg[i] = np.expand_dims(np.concatenate([np.expand_dims(Grid[...,5:10], -1), np.expand_dims(Tops[...,5:10], -1)], -1), 0)\n",
    "    g = np.expand_dims(Grid.flatten(order='F')[indexMap], -1)\n",
    "    t = np.expand_dims(Tops.flatten(order='F')[indexMap], -1)\n",
    "    xg[i] = np.expand_dims(np.concatenate([g, t], -1), 0)\n",
    "\n",
    "    m = np.load('data_npy_100_100_11/inputs_rock_rates_locs_time/x_{}.npz'.format(train_idx[i]))\n",
    "    # p = np.expand_dims(apply_mask(m['poro'], indexMap), -1)\n",
    "    # k = np.expand_dims(apply_mask(m['perm'], indexMap, mask_value=-9), -1)\n",
    "    p = np.expand_dims(m['poro'].flatten(order='F')[indexMap], -1)\n",
    "    k = np.expand_dims(m['perm'].flatten(order='F')[indexMap], -1)\n",
    "    xm[i] = np.concatenate([p, k], -1)\n",
    "\n",
    "    xw[i] = m['locs']\n",
    "    xc[i] = m['ctrl']\n",
    "    xt[i] = m['time']\n",
    "\n",
    "    dd = np.load('data_npy_100_100_11/outputs_pressure_saturation/y_{}.npz'.format(train_idx[i]))\n",
    "    prm = dd['pressure'].reshape(33, -1, order='F')[:,indexMap]\n",
    "    sam = dd['saturation'].reshape(33, -1, order='F')[:,indexMap]\n",
    "    yy[i,...,0] = prm\n",
    "    yy[i,...,1] = sam\n",
    "\n",
    "print('xm', xm.shape)\n",
    "print('xg', xg.shape)\n",
    "print('xw', xw.shape)\n",
    "print('xc', xc.shape)\n",
    "print('xt', xt.shape)\n",
    "print('yy', yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch: [{}/{}] - Loss: {:.4f} | Val Loss: {:.4f}'.format(epoch+1, num_epochs, logs['loss'], logs['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5134a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=AdamW(learning_rate=1e-3, weight_decay=4e-3), loss=custom_loss, metrics=['mse'])\n",
    "start = time()\n",
    "history = model.fit(x=[xm, xg, xw, xc, xt], y=yy, \n",
    "                    batch_size       = batch_size, \n",
    "                    epochs           = num_epochs, \n",
    "                    validation_split = 0.2, \n",
    "                    verbose          = False)\n",
    "train_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3740f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8302a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b344c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa6990f4",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
