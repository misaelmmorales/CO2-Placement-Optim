{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from utils import check_torch, pix2vid_dataset, calculate_metrics\n",
    "from utils import Units, DualCustomLoss, DualLpLoss, NeuralPix2Vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.3.1.post300 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): NVIDIA GeForce RTX 3090\n",
      "Torch device: cuda\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "NR, NT = 1272, 40\n",
    "NX, NY = 40, 40\n",
    "units  = Units()\n",
    "folder = 'simulations_40x40'\n",
    "device = check_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps: 40 | deltaT: [  0.5 250. ]\n",
      "tops2d: (40, 40)\n"
     ]
    }
   ],
   "source": [
    "tt = np.load('{}/timesteps.npz'.format(folder))\n",
    "timesteps, deltaTime = tt['timesteps'], tt['deltatime']\n",
    "t0steps = timesteps[:20]\n",
    "print('timesteps: {} | deltaT: {}'.format(len(timesteps), np.unique(deltaTime)))\n",
    "\n",
    "tops2d = sio.loadmat('{}/Gt.mat'.format(folder), simplify_cells=True)['Gt']['cells']['z'].reshape(NX,NY,order='F')\n",
    "print('tops2d: {}'.format(tops2d.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1272, 4, 40, 40) | c: (1272, 20, 5) | y1: (1272, 20, 2, 40, 40) | y2: (1272, 20, 1, 40, 40)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train - X:  torch.Size([1000, 4, 40, 40])     | c:  torch.Size([1000, 20, 5])\n",
      "        y1: torch.Size([1000, 20, 2, 40, 40]) | y2: torch.Size([1000, 20, 1, 40, 40])\n",
      "--------------------\n",
      "Valid - X:  torch.Size([136, 4, 40, 40])     | c:  torch.Size([136, 20, 5])\n",
      "        y1: torch.Size([136, 20, 2, 40, 40]) | y2: torch.Size([136, 20, 1, 40, 40])\n",
      "--------------------\n",
      "Test  - X:  torch.Size([136, 4, 40, 40])     | c:  torch.Size([136, 20, 5])\n",
      "        y1: torch.Size([136, 20, 2, 40, 40]) | y2: torch.Size([136, 20, 1, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "(Xt, ct, y1t, y2t, all_volumes, idx), (trainloader, validloader) = pix2vid_dataset(folder='simulations_40x40',\n",
    "                                                                                   batch_size=32,\n",
    "                                                                                   send_to_device=True,\n",
    "                                                                                   device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters: 4,261,815 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = NeuralPix2Vid(device=device).to(device)\n",
    "nparams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('# parameters: {:,} | device: {}'.format(nparams, model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xt: torch.Size([20, 4, 40, 40]) | ct: torch.Size([20, 20, 5])\n",
      "y1t: torch.Size([20, 20, 2, 40, 40]) | y2t: torch.Size([20, 20, 1, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "tempxt = Xt[:20]\n",
    "tempct = ct[:20]\n",
    "print('Xt: {} | ct: {}'.format(tempxt.shape, tempct.shape))\n",
    "\n",
    "tempy1t = y1t[:20]\n",
    "tempy2t = y2t[:20]\n",
    "print('y1t: {} | y2t: {}'.format(tempy1t.shape, tempy2t.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xt: (20, 4, 40, 40) | ct: (20, 20, 5)\n",
      "y1t: (20, 20, 2, 40, 40) | y2t: (20, 20, 1, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "tempx = Xt[:20].detach().cpu().numpy()\n",
    "tempc = ct[:20].detach().cpu().numpy()\n",
    "print('Xt: {} | ct: {}'.format(tempx.shape, tempc.shape))\n",
    "\n",
    "tempy1 = y1t[:20].detach().cpu().numpy()\n",
    "tempy2 = y2t[:20].detach().cpu().numpy()\n",
    "print('y1t: {} | y2t: {}'.format(tempy1.shape, tempy2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1p: (20, 20, 2, 40, 40) | y2p: torch.Size([20, 20, 1, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "tempy1p, temp2yp = model(tempxt, tempct)\n",
    "tempy1p, tempy2p = tempy1p.detach().cpu().numpy(), temp2yp.detach().cpu().numpy()\n",
    "print('y1p: {} | y2p: {}'.format(tempy1p.shape, temp2yp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "------------------------------------ METRICS ------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "R2   - pressure: -38.0806 | saturation (inj): -inf | saturation (monitor): -3731182106014536321589915418624.0000\n",
      "MSE  - pressure: 0.2121 | saturation (inj): 0.2468 | saturation (monitor): 0.2052\n",
      "SSIM - pressure: 0.0051 | saturation (inj): 0.0019 | saturation (monitor): 0.0074\n",
      "PSNR - pressure: 6.7344 | saturation (inj): 6.0769 | saturation (monitor): 6.8782\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misaelmorales/miniconda3/envs/rapid/lib/python3.11/site-packages/sklearn/metrics/_regression.py:886: RuntimeWarning: overflow encountered in divide\n",
      "  numerator[valid_score] / denominator[valid_score]\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(tempy1, tempy2, tempy1p, tempy2p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
