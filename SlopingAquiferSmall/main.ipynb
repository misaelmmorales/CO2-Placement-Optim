{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from utils import check_torch, pix2vid_dataset, calculate_metrics\n",
    "from utils import Units, DualCustomLoss, DualLpLoss, Pix2Vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.3.1.post300 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): NVIDIA GeForce RTX 3090\n",
      "Torch device: cuda\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "NR, NT = 1272, 40\n",
    "NX, NY = 40, 40\n",
    "units  = Units()\n",
    "folder = 'simulations_40x40'\n",
    "device = check_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps: 40 | deltaT: [  0.5 250. ]\n",
      "tops2d: (40, 40)\n"
     ]
    }
   ],
   "source": [
    "tt = np.load('{}/data/timesteps.npz'.format(folder))\n",
    "timesteps, deltaTime = tt['timesteps'], tt['deltatime']\n",
    "t0steps = timesteps[:20]\n",
    "print('timesteps: {} | deltaT: {}'.format(len(timesteps), np.unique(deltaTime)))\n",
    "\n",
    "tops2d = sio.loadmat('{}/grids/Gt.mat'.format(folder), simplify_cells=True)['Gt']['cells']['z'].reshape(NX,NY,order='F')\n",
    "print('tops2d: {}'.format(tops2d.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1272, 4, 40, 40) | c: (1272, 20, 5) | y1: (1272, 20, 2, 40, 40) | y2: (1272, 20, 1, 40, 40)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train - X:  torch.Size([1000, 4, 40, 40])     | c:  torch.Size([1000, 20, 5])\n",
      "        y1: torch.Size([1000, 20, 2, 40, 40]) | y2: torch.Size([1000, 20, 1, 40, 40])\n",
      "--------------------\n",
      "Valid - X:  torch.Size([136, 4, 40, 40])     | c:  torch.Size([136, 20, 5])\n",
      "        y1: torch.Size([136, 20, 2, 40, 40]) | y2: torch.Size([136, 20, 1, 40, 40])\n",
      "--------------------\n",
      "Test  - X:  torch.Size([136, 4, 40, 40])     | c:  torch.Size([136, 20, 5])\n",
      "        y1: torch.Size([136, 20, 2, 40, 40]) | y2: torch.Size([136, 20, 1, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "(Xt, ct, y1t, y2t, all_volumes, idx), (trainloader, validloader) = pix2vid_dataset(folder='simulations_40x40/data',\n",
    "                                                                                   batch_size=32,\n",
    "                                                                                   send_to_device=True,\n",
    "                                                                                   device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pix2vid - # parameters: 80,343 | device: cuda\n",
      "Neural  - # parameters: 4,261,815 | device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = Pix2Vid(device=device, spectral=False).to(device)\n",
    "model.load_state_dict(torch.load('pix2vid_model.pth'))\n",
    "model.eval()\n",
    "nparams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('pix2vid - # parameters: {:,} | device: {}'.format(nparams, model.device))\n",
    "\n",
    "neural = Pix2Vid(device=device, spectral=True).to(device)\n",
    "neural.load_state_dict(torch.load('neural-pix2vid_model.pth'))\n",
    "neural.eval()\n",
    "nparams = sum(p.numel() for p in neural.parameters() if p.requires_grad)\n",
    "print('Neural  - # parameters: {:,} | device: {}'.format(nparams, neural.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xt: torch.Size([20, 4, 40, 40]) | ct: torch.Size([20, 20, 5])\n",
      "y1t: torch.Size([20, 20, 2, 40, 40]) | y2t: torch.Size([20, 20, 1, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "tempxt = Xt[:20]\n",
    "tempct = ct[:20]\n",
    "print('Xt: {} | ct: {}'.format(tempxt.shape, tempct.shape))\n",
    "\n",
    "tempy1t = y1t[:20]\n",
    "tempy2t = y2t[:20]\n",
    "print('y1t: {} | y2t: {}'.format(tempy1t.shape, tempy2t.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xt: (20, 4, 40, 40) | ct: (20, 20, 5)\n",
      "y1t: (20, 20, 2, 40, 40) | y2t: (20, 20, 1, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "tempx = Xt[:20].detach().cpu().numpy()\n",
    "tempc = ct[:20].detach().cpu().numpy()\n",
    "print('Xt: {} | ct: {}'.format(tempx.shape, tempc.shape))\n",
    "\n",
    "tempy1 = y1t[:20].detach().cpu().numpy()\n",
    "tempy2 = y2t[:20].detach().cpu().numpy()\n",
    "print('y1t: {} | y2t: {}'.format(tempy1.shape, tempy2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1p: (20, 20, 2, 40, 40) | y2p: torch.Size([20, 20, 1, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "tempy1p, temp2yp = model(tempxt, tempct)\n",
    "tempy1p, tempy2p = tempy1p.detach().cpu().numpy(), temp2yp.detach().cpu().numpy()\n",
    "print('y1p: {} | y2p: {}'.format(tempy1p.shape, temp2yp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misaelmorales/miniconda3/envs/rapid/lib/python3.11/site-packages/sklearn/metrics/_regression.py:886: RuntimeWarning: overflow encountered in divide\n",
      "  numerator[valid_score] / denominator[valid_score]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "------------------------------------ METRICS ------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "R2   - pressure: -6.9859 | saturation (inj): -inf | saturation (monitor): -68690919507446120485253808128.0000\n",
      "MSE  - pressure: 0.1017 | saturation (inj): 0.0584 | saturation (monitor): 0.0849\n",
      "SSIM - pressure: 0.0207 | saturation (inj): 0.0543 | saturation (monitor): 0.0184\n",
      "PSNR - pressure: 9.9282 | saturation (inj): 12.3358 | saturation (monitor): 10.7090\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(tempy1, tempy2, tempy1p, tempy2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 10, figsize=(14,6), sharex=True, sharey=True)\n",
    "for i in range(4):\n",
    "    for j in range(10):\n",
    "        k = j*2+1\n",
    "        ax = axs[i,j]\n",
    "        d = np.ma.masked_where(tempy2[i,k,-1]<0.01, tempy2[i,k,-1])\n",
    "        ax.imshow(tops2d, cmap='binary', alpha=0.33)\n",
    "        im = ax.imshow(d, cmap='turbo', vmin=0, vmax=1)\n",
    "        plt.colorbar(im, pad=0.04, fraction=0.046)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 10, figsize=(14,6), sharex=True, sharey=True)\n",
    "for i in range(4):\n",
    "    for j in range(10):\n",
    "        k = j*2+1\n",
    "        ax = axs[i,j]\n",
    "        #d = np.ma.masked_where(tempy2p[i,k,-1]<0.01, tempy2[i,k,-1])\n",
    "        d = tempy2p[i,k,-1]\n",
    "        ax.imshow(tops2d, cmap='binary', alpha=0.33)\n",
    "        im = ax.imshow(d, cmap='turbo', vmin=0, vmax=1)\n",
    "        plt.colorbar(im, pad=0.04, fraction=0.046)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
