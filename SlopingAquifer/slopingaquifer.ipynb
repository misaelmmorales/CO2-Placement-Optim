{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "from keras import layers, regularizers, optimizers, losses, metrics, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcite(Layer):\n",
    "    def __init__(self, ratio=4, **kwargs):\n",
    "        super(SqueezeExcite, self).__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1]\n",
    "        self.squeeze = layers.GlobalAveragePooling2D()\n",
    "        self.excite1 = layers.Dense(channels // self.ratio, activation='relu')\n",
    "        self.excite2 = layers.Dense(channels, activation='sigmoid')\n",
    "        super(SqueezeExcite, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.squeeze(inputs)\n",
    "        x = self.excite1(x)\n",
    "        x = self.excite2(x)\n",
    "        x = layers.Reshape((1, 1, x.shape[-1]))(x)\n",
    "        s = layers.Multiply()([inputs, x])\n",
    "        return layers.Add()([inputs, s])\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(inp, filt, k=3, pad='same', drop=0.1, pool=(2,2)):\n",
    "    _ = layers.Conv2D(filt, k, activity_regularizer=regularizers.l1(1e-6), padding=pad)(inp)\n",
    "    _ = SqueezeExcite()(_)\n",
    "    _ = layers.GroupNormalization(groups=-1)(_)\n",
    "    _ = layers.PReLU()(_)\n",
    "    _ = layers.MaxPooling2D(pool)(_)\n",
    "    _ = layers.SpatialDropout2D(drop)(_)\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_decoder(z_input, residuals, rnn_filters=[16,64,256], previous_timestep=None, \n",
    "                      dropout=0.1, leaky_slope=0.3, out_channels:int=2):\n",
    "    \n",
    "    def recurrent_step(inp, filt, res, kern=3, pad='same', drop=dropout):\n",
    "        y = layers.ConvLSTM2D(filt, kern, padding=pad)(inp)\n",
    "        y = layers.GroupNormalization(groups=-1)(y)\n",
    "        y = layers.LeakyReLU(leaky_slope)(y)\n",
    "        y = layers.Conv2DTranspose(filt, kern, padding=pad, strides=2)(y)\n",
    "        y = layers.SpatialDropout2D(drop)(y)\n",
    "        y = layers.Concatenate()([y, res])\n",
    "        y = layers.Conv2D(filt, kern, padding=pad)(y)\n",
    "        y = layers.Activation('sigmoid')(y)\n",
    "        y = tf.expand_dims(y,1)\n",
    "        return y\n",
    "    \n",
    "    def recurrent_last(inp, filt, kern=3, pad='same', drop=dropout):\n",
    "        y = layers.ConvLSTM2D(filt, kern, padding=pad)(inp)\n",
    "        y = layers.GroupNormalization(groups=-1)(y)\n",
    "        y = layers.LeakyReLU(leaky_slope)(y)\n",
    "        y = layers.Conv2DTranspose(filt, kern, padding=pad, strides=2)(y)\n",
    "        y = layers.SpatialDropout2D(drop)(y)\n",
    "        y = layers.Conv2D(out_channels, kern, padding=pad)(y)\n",
    "        y = layers.Activation('sigmoid')(y)\n",
    "        y = tf.expand_dims(y, 1)\n",
    "        return y\n",
    "    \n",
    "    _ = tf.expand_dims(z_input, 1)\n",
    "    _ = recurrent_step(_, rnn_filters[0], residuals[0])\n",
    "    _ = recurrent_step(_, rnn_filters[1], residuals[1])\n",
    "    _ = recurrent_last(_, rnn_filters[2])\n",
    "    \n",
    "    if previous_timestep != None:\n",
    "        _ = layers.Concatenate(axis=1)([previous_timestep, _])\n",
    "    \n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    inputs = layers.Input(shape=(160, 160, 5))\n",
    "\n",
    "    # Encoder\n",
    "    x1 = encoder_layer(inputs, 16)\n",
    "    x2 = encoder_layer(x1, 64)\n",
    "    x3 = encoder_layer(x2, 256)\n",
    "\n",
    "    # Decoder\n",
    "    _ = recurrent_decoder(x3, [x2, x1])\n",
    "\n",
    "    outputs = x3\n",
    "    return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m temp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m5\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmake_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# parameters: \u001b[39m\u001b[38;5;132;01m{:,}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mcount_params()))\n",
      "Cell \u001b[0;32mIn[166], line 10\u001b[0m, in \u001b[0;36mmake_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m x3 \u001b[38;5;241m=\u001b[39m encoder_layer(x2, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Decoder\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mrecurrent_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m x3\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs)\n",
      "Cell \u001b[0;32mIn[165], line 27\u001b[0m, in \u001b[0;36mrecurrent_decoder\u001b[0;34m(z_input, residuals, rnn_filters, previous_timestep, dropout, leaky_slope, out_channels)\u001b[0m\n\u001b[1;32m     24\u001b[0m     y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(y, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[0;32m---> 27\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m recurrent_step(_, rnn_filters[\u001b[38;5;241m0\u001b[39m], residuals[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     29\u001b[0m _ \u001b[38;5;241m=\u001b[39m recurrent_step(_, rnn_filters[\u001b[38;5;241m1\u001b[39m], residuals[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/flow/lib/python3.9/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/miniconda3/envs/flow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/flow/lib/python3.9/site-packages/keras/src/backend/common/keras_tensor.py:91\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "temp = np.random.normal(size=(1, 160, 160, 5)).astype(np.float32)\n",
    "model = make_model()\n",
    "print('# parameters: {:,}'.format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: (1, 80, 80, 16) | x2: (1, 40, 40, 64) | x3: (1, 20, 20, 256)\n",
      "y1: (1, 1, 160, 160, 2)\n"
     ]
    }
   ],
   "source": [
    "x1 = encoder_layer(temp, 16)\n",
    "x2 = encoder_layer(x1, 64)\n",
    "x3 = encoder_layer(x2, 256)\n",
    "print('x1: {} | x2: {} | x3: {}'.format(x1.shape, x2.shape, x3.shape))\n",
    "\n",
    "zz = tf.expand_dims(x3, 1)\n",
    "y1 = recurrent_step(zz, 256, x2)\n",
    "y1 = recurrent_step(y1, 64, x1)\n",
    "y1 = recurrent_last(y1, 16)\n",
    "print('y1: {}'.format(y1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
