{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "from keras.callbacks import Callback\n",
    "from keras import layers, regularizers, optimizers, losses, metrics, callbacks\n",
    "\n",
    "NUM_REALIZATIONS = 20\n",
    "X_CHANNELS = 4\n",
    "Y_CHANNELS = 2\n",
    "NX  = 160\n",
    "NY  = 160\n",
    "NTT = 60\n",
    "NT1 = 30\n",
    "NT0 = 24\n",
    "\n",
    "EPOCHS = 101\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-6\n",
    "MONITOR = 10\n",
    "\n",
    "sec2year   = 365.25 * 24 * 60 * 60\n",
    "Darcy      = 9.869233e-13\n",
    "psi2pascal = 6894.76\n",
    "co2_rho    = 686.5266\n",
    "mega       = 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "TF version: 2.15.0 | # Device(s) available: 2\n",
      "TF Built with CUDA? True | CUDA: 12.2 | cuDNN: 8\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_tf_gpu():\n",
    "    sys_info = tf.sysconfig.get_build_info()\n",
    "    version, cuda, cudnn = tf.__version__, sys_info[\"cuda_version\"], sys_info[\"cudnn_version\"]\n",
    "    count = len(tf.config.experimental.list_physical_devices())\n",
    "    name  = [device.name for device in tf.config.experimental.list_physical_devices('GPU')]\n",
    "    print('-'*60)\n",
    "    print('----------------------- VERSION INFO -----------------------')\n",
    "    print('TF version: {} | # Device(s) available: {}'.format(version, count))\n",
    "    print('TF Built with CUDA? {} | CUDA: {} | cuDNN: {}'.format(tf.test.is_built_with_cuda(), cuda, cudnn))\n",
    "    print(tf.config.list_physical_devices()[-1])\n",
    "    print('-'*60+'\\n')\n",
    "    return None\n",
    "\n",
    "check_tf_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridVE = sio.loadmat('Gt.mat', simplify_cells=True)['Gt']\n",
    "tops2d = -gridVE['cells']['z'].reshape(NX,NY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.zeros((NUM_REALIZATIONS, X_CHANNELS, NX, NY))\n",
    "c_data = np.zeros((NUM_REALIZATIONS, 5, 30))\n",
    "y1_data = np.zeros((NUM_REALIZATIONS, Y_CHANNELS, NX, NY, NT1))\n",
    "y2_data = np.zeros((NUM_REALIZATIONS, Y_CHANNELS, NX, NY, NT1))\n",
    "\n",
    "for i in tqdm(range(NUM_REALIZATIONS), desc='Loading data'):\n",
    "    X_data[i] = np.load('data/features/features_{}.npy'.format(i))[:-1,...,0]\n",
    "\n",
    "    c = sio.loadmat('controls/controls_{}.mat'.format(i), simplify_cells=True)['var']\n",
    "    if len(c.shape) == 1:\n",
    "        c = c.reshape(1, -1)\n",
    "    c_data[i,:c.shape[0]] = c\n",
    "\n",
    "    y = np.load('data/targets/targets_{}.npy'.format(i))\n",
    "    y1_data[i] = y[...,:NT1]\n",
    "    y2_data[i] = y[...,NT1:]\n",
    "\n",
    "X_data = np.moveaxis(X_data, 1, -1)\n",
    "c_data = np.moveaxis(c_data, 1, -1)\n",
    "y1_data = np.moveaxis(np.moveaxis(y1_data, -1, 2), 1, -1)\n",
    "y2_data = np.moveaxis(np.moveaxis(y2_data, -1, 2), 1, -1)\n",
    "\n",
    "print('X: {} | c: {}'.format(X_data.shape, c_data.shape))\n",
    "print('y1: {} | y2: {}'.format(y1_data.shape, y2_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = []\n",
    "dd = sio.loadmat('states/states_0.mat', simplify_cells=True)['var']\n",
    "for j in range(NTT):\n",
    "    timesteps.append(dd[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = np.repeat(np.expand_dims(tops2d, 0), NUM_REALIZATIONS, axis=0)\n",
    "perm = np.zeros((NUM_REALIZATIONS, NX, NY))\n",
    "poro = np.zeros((NUM_REALIZATIONS, NX, NY))\n",
    "well = np.zeros((NUM_REALIZATIONS, NX, NY))\n",
    "ctrl = np.zeros((NUM_REALIZATIONS, 5, 30))\n",
    "pres = np.zeros((NUM_REALIZATIONS, NTT, NX, NY))\n",
    "satu = np.zeros((NUM_REALIZATIONS, NTT, NX, NY))\n",
    "\n",
    "for i in tqdm(range(NUM_REALIZATIONS), desc='Loading data'):\n",
    "    rock = sio.loadmat('rock/VE2d/mat/rock2d_{}.mat'.format(i), simplify_cells=True)['var']\n",
    "    perm[i] = rock['perm'].reshape(NX,NY) / Darcy\n",
    "    poro[i] = rock['poro'].reshape(NX,NY)\n",
    "\n",
    "    ww = sio.loadmat('well_locs/well_locs_{}.mat'.format(i), simplify_cells=True)['var'] -1\n",
    "    cc = sio.loadmat('controls/controls_{}.mat'.format(i), simplify_cells=True)['var'] * sec2year*co2_rho/1e3/mega\n",
    "\n",
    "    if len(cc.shape)==1:\n",
    "        cc = cc.reshape(1, -1)\n",
    "    if len(ww.shape)==1:\n",
    "        ww = ww.reshape(1, -1)\n",
    "\n",
    "    well[i, ww[:,1], ww[:,0]] = 1\n",
    "    ctrl[i, :cc.shape[0]] = cc\n",
    "\n",
    "    dd = sio.loadmat('states/states_{}.mat'.format(i), simplify_cells=True)['var']\n",
    "    for j in range(NTT):\n",
    "        pres[i,j] = dd[j]['pressure'].reshape(NX,NY) / psi2pascal\n",
    "        satu[i,j] = dd[j]['s'].reshape(NX,NY)\n",
    "\n",
    "\n",
    "ctrl = np.moveaxis(ctrl, -1, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 12, figsize=(15,6), sharex=True, sharey=True)\n",
    "for i in range(5):\n",
    "    for j in range(12):\n",
    "        ax = axs[i,j]\n",
    "        k = j*5\n",
    "        ax.imshow(satu[i,k], cmap='jet')\n",
    "        ax.set_title('t={}'.format(k)) if i==0 else None\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(ctrl[i], 'magma')\n",
    "    plt.colorbar(pad=0.04, fraction=0.046)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(range(len(X_data)), 80, replace=False)\n",
    "test_idx  = np.setdiff1d(range(len(X_data)), train_idx)\n",
    "\n",
    "X_train = X_data[train_idx]\n",
    "c_train = c_data[train_idx, :NT0]\n",
    "y1_train = y1_data[train_idx, :NT0]\n",
    "y2_train = y2_data[train_idx, :NT0]\n",
    "\n",
    "X_test = X_data[test_idx]\n",
    "c_test = c_data[test_idx, :NT0]\n",
    "y1_test = y1_data[test_idx, :NT0]\n",
    "y2_test = y2_data[test_idx, :NT0]\n",
    "\n",
    "print('X_train:  {}     | c_train: {}'.format(X_train.shape, c_train.shape))\n",
    "print('y1_train: {} | y2_train: {}'.format(y1_train.shape, y2_train.shape))\n",
    "print('-'*70)\n",
    "print('X_test:  {}     | c_test: {}'.format(X_test.shape, c_test.shape))\n",
    "print('y1_test: {} | y2_test: {}'.format(y1_test.shape, y2_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(12,5), sharex=True, sharey=True)\n",
    "for j in range(5):\n",
    "    ax = axs[j]\n",
    "    i = j*10+10\n",
    "    ax.imshow(c_data[i], aspect='auto', cmap='inferno')\n",
    "    ax.set(yticks=np.arange(30), yticklabels=np.arange(1,31), xticks=range(5), xticklabels=['W{}'.format(i) for i in range(1,6)])\n",
    "    ax.set(xlabel='Wells', ylabel='Injectors' if i==0 else None, title='R {}'.format(i))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Poro','LogPerm','Tops','Wells']\n",
    "fig, axs = plt.subplots(4, 10, figsize=(15,5), sharex=True, sharey=True)\n",
    "for i in range(4):\n",
    "    for j in range(10):\n",
    "        ax = axs[i,j]\n",
    "        k = j*10\n",
    "        ax.imshow(X_data[k,...,i], cmap='turbo')\n",
    "        ax.set(title='R {}'.format(k) if i==0 else None)\n",
    "        ax.set(ylabel=labels[i]) if j==0 else None\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcite(Layer):\n",
    "    def __init__(self, ratio=4, **kwargs):\n",
    "        super(SqueezeExcite, self).__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1]\n",
    "        self.squeeze = layers.GlobalAveragePooling2D()\n",
    "        self.excite1 = layers.Dense(channels // self.ratio, activation='relu')\n",
    "        self.excite2 = layers.Dense(channels, activation='sigmoid')\n",
    "        super(SqueezeExcite, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.squeeze(inputs)\n",
    "        x = self.excite1(x)\n",
    "        x = self.excite2(x)\n",
    "        x = layers.Reshape((1, 1, x.shape[-1]))(x)\n",
    "        s = layers.Multiply()([inputs, x])\n",
    "        return layers.Add()([inputs, s])\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(inp, filt, k=3, pad='same', drop=0.1, pool=(2,2)):\n",
    "    _ = layers.Conv2D(filt, k, activity_regularizer=regularizers.l1(1e-6), padding=pad)(inp)\n",
    "    _ = SqueezeExcite()(_)\n",
    "    _ = layers.GroupNormalization(groups=-1)(_)\n",
    "    _ = layers.PReLU()(_)\n",
    "    _ = layers.MaxPooling2D(pool)(_)\n",
    "    _ = layers.SpatialDropout2D(drop)(_)\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lifting_layer(inp, dim):\n",
    "    _ = layers.Dense(dim)(inp)\n",
    "    _ = layers.Activation('gelu')(_)\n",
    "    _ = layers.Dropout(0.1)(_)\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_step(inp, filt, res, kern=3, pad='same', drop=0.0, leaky_slope=0.3):\n",
    "    y = layers.ConvLSTM2D(filt, kern, padding=pad)(inp)\n",
    "    y = layers.GroupNormalization(groups=-1)(y)\n",
    "    y = layers.LeakyReLU(leaky_slope)(y)\n",
    "    y = layers.Conv2DTranspose(filt, kern, padding=pad, strides=2)(y)\n",
    "    y = layers.SpatialDropout2D(drop)(y)\n",
    "    y = layers.Concatenate()([y, res])\n",
    "    y = layers.Conv2D(filt, kern, padding=pad)(y)\n",
    "    y = layers.Activation('sigmoid')(y)\n",
    "    y = keras.ops.expand_dims(y,1)\n",
    "    return y\n",
    "\n",
    "def recurrent_last(inp, filt, kern=3, pad='same', drop=0.0, leaky_slope=0.3, out_channels=2):\n",
    "    y = layers.ConvLSTM2D(filt, kern, padding=pad)(inp)\n",
    "    y = layers.GroupNormalization(groups=-1)(y)\n",
    "    y = layers.LeakyReLU(leaky_slope)(y)\n",
    "    y = layers.Conv2DTranspose(filt, kern, padding=pad, strides=2)(y)\n",
    "    y = layers.SpatialDropout2D(drop)(y)\n",
    "    y = layers.Conv2D(out_channels, kern, padding=pad)(y)\n",
    "    y = layers.Activation('sigmoid')(y)\n",
    "    y = keras.ops.expand_dims(y, 1)\n",
    "    return y\n",
    "\n",
    "def conditional_recurrent_decoder(z_input, c_input, residuals, rnn_filters=[16,64,256], \n",
    "                                  previous_timestep=None, dropout=0.1, leaky_slope=0.3, out_channels:int=2):\n",
    "    zz = keras.ops.expand_dims(z_input, 1)\n",
    "    cc = keras.ops.expand_dims(c_input, 1)\n",
    "    _ = keras.ops.einsum('bthwc,btc->bthwc', zz, cc)\n",
    "    _ = recurrent_step(_, rnn_filters[0], residuals[0], drop=dropout, leaky_slope=leaky_slope)\n",
    "    _ = recurrent_step(_, rnn_filters[1], residuals[1], drop=dropout, leaky_slope=leaky_slope)\n",
    "    _ = recurrent_last(_, rnn_filters[2], drop=dropout, leaky_slope=leaky_slope, out_channels=out_channels)\n",
    "    if previous_timestep is not None:\n",
    "        _ = layers.Concatenate(axis=1)([previous_timestep, _])\n",
    "    return _\n",
    "\n",
    "def unconditional_recurrent_decoder(z_input, residuals, rnn_filters=[16,64,256], \n",
    "                                    previous_timestep=None, dropout=0.1, leaky_slope=0.3, out_channels:int=2):    \n",
    "    _ = keras.ops.expand_dims(z_input, 1)\n",
    "    _ = recurrent_step(_, rnn_filters[0], residuals[0], drop=dropout, leaky_slope=leaky_slope)\n",
    "    _ = recurrent_step(_, rnn_filters[1], residuals[1], drop=dropout, leaky_slope=leaky_slope)\n",
    "    _ = recurrent_last(_, rnn_filters[2], drop=dropout, leaky_slope=leaky_slope, out_channels=out_channels)\n",
    "    if previous_timestep is not None:\n",
    "        _ = layers.Concatenate(axis=1)([previous_timestep, _])\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(timesteps=24, verbose:bool=True):\n",
    "    x_inp = layers.Input(shape=(NX, NY, X_CHANNELS))\n",
    "    c_inp = layers.Input(shape=(timesteps, 5))\n",
    "\n",
    "    # Model 1\n",
    "    x1 = encoder_layer(x_inp, 16)\n",
    "    x2 = encoder_layer(x1, 64)\n",
    "    x3 = encoder_layer(x2, 256)\n",
    "    cc = lifting_layer(c_inp, 256)\n",
    "    t1 = None\n",
    "    for t in range(timesteps):\n",
    "        if t==0:\n",
    "            t1 = conditional_recurrent_decoder(x3, cc[:,t], [x2, x1])\n",
    "        else:\n",
    "            t1 = conditional_recurrent_decoder(x3, cc[:,t], [x2, x1], previous_timestep=t1) \n",
    "\n",
    "    # Model 2\n",
    "    y_inp = layers.Concatenate(axis=-1)([x_inp, t1[:,-1]])\n",
    "    y1 = encoder_layer(y_inp, 16)\n",
    "    y2 = encoder_layer(y1, 64)\n",
    "    y3 = encoder_layer(y2, 256)\n",
    "    t2 = None\n",
    "    for t in range(timesteps):\n",
    "        if t==0:\n",
    "            t2 = unconditional_recurrent_decoder(y3, [y2, y1])\n",
    "        else:\n",
    "            t2 = unconditional_recurrent_decoder(y3, [y2, y1], previous_timestep=t2) \n",
    "\n",
    "    model = Model(inputs=[x_inp, c_inp], outputs=[t1, t2])\n",
    "\n",
    "    if verbose:\n",
    "        print('# parameters: {:,}'.format(model.count_params()))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(true, pred, alpha=0.8, beta=0.8, gamma=0.8):\n",
    "\n",
    "    # perceptual loss\n",
    "    ssim_loss = tf.reduce_mean(1.0 - tf.image.ssim(true, pred, max_val=1.0))\n",
    "    psnr_loss = tf.reduce_mean(1.0 / tf.image.psnr(true, pred, max_val=1.0))\n",
    "    perceptual = gamma * ssim_loss + (1 - gamma) * psnr_loss\n",
    "    \n",
    "    # reconstruction loss\n",
    "    mse_loss = tf.reduce_mean(tf.square(true - pred))\n",
    "    mae_loss = tf.reduce_mean(tf.abs(true - pred))\n",
    "    reconstruction = beta * mse_loss + (1 - beta) * mae_loss\n",
    "    \n",
    "    # total loss\n",
    "    return alpha * reconstruction + (1 - alpha) * perceptual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonitorCallback(Callback):\n",
    "    def __init__(self, monitor:int=10):\n",
    "        super(MonitorCallback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch+1) % self.monitor == 0:\n",
    "            print('Epoch: {} | Loss: {:.5f} | Val Loss: {:.5f}'.format(epoch+1, logs['loss'], logs['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mse','mse'])\n",
    "\n",
    "esCallback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
    "mcCallback = keras.callbacks.ModelCheckpoint('pix2vid-opt.keras', monitor='val_accuracy', save_best_only=True)\n",
    "customCBs  = [MonitorCallback(monitor=MONITOR), esCallback, mcCallback]\n",
    "\n",
    "start = time()\n",
    "fit = model.fit(x=[X_train, c_train], y=[y1_train, y2_train],\n",
    "                batch_size       = BATCH_SIZE,\n",
    "                epochs           = EPOCHS,\n",
    "                validation_split = 0.2,\n",
    "                shuffle          = True,\n",
    "                callbacks        = customCBs,\n",
    "                verbose          = 0)\n",
    "print('-'*30+'\\n'+'Training time: {:.2f} minutes'.format((time()-start)/60))\n",
    "model.save('pix2vid-opt.keras')\n",
    "pd.DataFrame(fit.history).to_csv('pix2vid-opt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
